{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "hw5_thai_skip_gram_homework_for_student_v2020s2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icekang/NLP_2021/blob/main/hw5_thai_skip_gram_homework_for_student_v2020s2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko8K6ntRi-W6"
      },
      "source": [
        "# Homework: Word Embedding\n",
        "\n",
        "In this exercise, you will work on the skip-gram neural network architecture for Word2Vec. You will be using Keras to train your model. \n",
        "\n",
        "You must complete the following tasks:\n",
        "1. Read/clean text files\n",
        "2. Indexing (Assign a number to each word)\n",
        "3. Create skip-grams (inputs for your model)\n",
        "4. Create the skip-gram neural network model\n",
        "5. Visualization\n",
        "6. Evaluation (Using pre-trained, not using pre-trained)\n",
        "    (classify topic from 4 categories) \n",
        "    \n",
        "This notebook assumes you have already installed Tensorflow and Keras with python3 and had GPU enabled. If you run this exercise on GCloud using the provided disk image you are all set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw11OhLsi-W8"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import glob\n",
        "import re\n",
        "import random\n",
        "import collections\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import GRU, Dropout\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input, Dense, Masking, Conv1D, Bidirectional\n",
        "from tensorflow.python.keras.layers.merge import Dot\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.keras.utils.data_utils import get_file\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdYpL3Uyi-XD"
      },
      "source": [
        "# Step 1: Read/clean text files\n",
        "\n",
        "The given code can be used to processed the pre-tokenzied text file from the wikipedia corpus. In your homework, you must replace those text files with raw text files.  You must use your own tokenizer to process your text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wco1eVRVzn6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0953a5-c888-43c6-d446-d69ec76976a7"
      },
      "source": [
        "!wget https://www.dropbox.com/s/eexden7246sgfzf/BEST-TrainingSet.zip\n",
        "!wget https://www.dropbox.com/s/n87fiy25f2yc3gt/wiki.zip\n",
        "!unzip wiki.zip\n",
        "\n",
        "!unzip BEST-TrainingSet.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-21 14:42:45--  https://www.dropbox.com/s/eexden7246sgfzf/BEST-TrainingSet.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6027:18::a27d:4812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/eexden7246sgfzf/BEST-TrainingSet.zip [following]\n",
            "--2021-02-21 14:42:46--  https://www.dropbox.com/s/raw/eexden7246sgfzf/BEST-TrainingSet.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb71c975f0df6a64784dc9a458a.dl.dropboxusercontent.com/cd/0/inline/BJXZFDvX7A-m3boFwFkLTtFD5PGwTGgsaRLOweTlyOyNAAVLTrCWlpBMFHBFiJ7NR261gpej6GMnwoP8EEF770U2LY-hYsmNOOTvVxAqrArbsMv94kDt3yG1YdABeaqLm9g/file# [following]\n",
            "--2021-02-21 14:42:46--  https://ucb71c975f0df6a64784dc9a458a.dl.dropboxusercontent.com/cd/0/inline/BJXZFDvX7A-m3boFwFkLTtFD5PGwTGgsaRLOweTlyOyNAAVLTrCWlpBMFHBFiJ7NR261gpej6GMnwoP8EEF770U2LY-hYsmNOOTvVxAqrArbsMv94kDt3yG1YdABeaqLm9g/file\n",
            "Resolving ucb71c975f0df6a64784dc9a458a.dl.dropboxusercontent.com (ucb71c975f0df6a64784dc9a458a.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to ucb71c975f0df6a64784dc9a458a.dl.dropboxusercontent.com (ucb71c975f0df6a64784dc9a458a.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BJXaYL2VPTbcm_78-LEIA5nTBTYAU5MIcrvX-REblzHoKegbl8kAKUatiVfVL_tgqxWxErVlr8OApDcRNsH9f6LZcTJCUgOLbo7ioOoKFTgb5ZwyjrhV6ueMDgSAc0IZtgPC24ddQ8PRqvSPf9_nWJhTVYUvQfVdP4W-2DxZLyty89RDBI3_dbSQaT-1wiRQocn59kClmio7qCW1keb0KvYHPOIdeTB258IJPjyMyrJsNyBN2WYEhZgsBxln_G4TXhxvJVNf3JXIVUh-Rs29EeGuxcENA_Twm65aBWtiF_ZyjxUJmvZcUJ6fwB3UPVkN4RKMoOGg7Zr9Bgf75trs6wnZY_BcYAUWxE6hVyoajlV2aw/file [following]\n",
            "--2021-02-21 14:42:47--  https://ucb71c975f0df6a64784dc9a458a.dl.dropboxusercontent.com/cd/0/inline2/BJXaYL2VPTbcm_78-LEIA5nTBTYAU5MIcrvX-REblzHoKegbl8kAKUatiVfVL_tgqxWxErVlr8OApDcRNsH9f6LZcTJCUgOLbo7ioOoKFTgb5ZwyjrhV6ueMDgSAc0IZtgPC24ddQ8PRqvSPf9_nWJhTVYUvQfVdP4W-2DxZLyty89RDBI3_dbSQaT-1wiRQocn59kClmio7qCW1keb0KvYHPOIdeTB258IJPjyMyrJsNyBN2WYEhZgsBxln_G4TXhxvJVNf3JXIVUh-Rs29EeGuxcENA_Twm65aBWtiF_ZyjxUJmvZcUJ6fwB3UPVkN4RKMoOGg7Zr9Bgf75trs6wnZY_BcYAUWxE6hVyoajlV2aw/file\n",
            "Reusing existing connection to ucb71c975f0df6a64784dc9a458a.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13122229 (13M) [application/zip]\n",
            "Saving to: ‘BEST-TrainingSet.zip’\n",
            "\n",
            "BEST-TrainingSet.zi 100%[===================>]  12.51M  9.00MB/s    in 1.4s    \n",
            "\n",
            "2021-02-21 14:42:49 (9.00 MB/s) - ‘BEST-TrainingSet.zip’ saved [13122229/13122229]\n",
            "\n",
            "--2021-02-21 14:42:50--  https://www.dropbox.com/s/n87fiy25f2yc3gt/wiki.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6027:18::a27d:4812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/n87fiy25f2yc3gt/wiki.zip [following]\n",
            "--2021-02-21 14:42:50--  https://www.dropbox.com/s/raw/n87fiy25f2yc3gt/wiki.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc0cd506fd7def7b84ce00cd1e0.dl.dropboxusercontent.com/cd/0/inline/BJVR2F3CkJmNlqSsn3I4KS2IrSCSqL3tDf5OOgHw-JUb4g590lH0FkCUdmRwgFCcVrO2Qcnrnfhs51Q_yWI9YM-YE7Tv2_fRPe-CuHt-LLA8KKCffnkzW2Bir62bNIe9at8/file# [following]\n",
            "--2021-02-21 14:42:50--  https://ucc0cd506fd7def7b84ce00cd1e0.dl.dropboxusercontent.com/cd/0/inline/BJVR2F3CkJmNlqSsn3I4KS2IrSCSqL3tDf5OOgHw-JUb4g590lH0FkCUdmRwgFCcVrO2Qcnrnfhs51Q_yWI9YM-YE7Tv2_fRPe-CuHt-LLA8KKCffnkzW2Bir62bNIe9at8/file\n",
            "Resolving ucc0cd506fd7def7b84ce00cd1e0.dl.dropboxusercontent.com (ucc0cd506fd7def7b84ce00cd1e0.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to ucc0cd506fd7def7b84ce00cd1e0.dl.dropboxusercontent.com (ucc0cd506fd7def7b84ce00cd1e0.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BJV-HLDNn4_K2LjbSQmfAKTTenb6oaY7FgclPkv2ciEXBNz7OPTwH8tb6iHhXMELP48fZy74I00Jdxbe89TTN1xc5jvd0bcjxZV6kl6COUUUnE_iZT3oUGbOlT3UHFg7awZ3Q69ioKsMt5BrnLb1MCybWQz53hZaC1kMD1BPoaly3jaMOMWe-QNoTpdrlw4b_ynp4bEuBZYIgNogJjfbkuZonXeqQXasUCdJ9tZgrbiXsL2P7TFinN6EwCsD-AC5Oez-QRDA2K2fGFC7s4JJOLwSfZtwIKm-lqvTWTpk5LSstM0uct4BKVRqLJphQ3lvhi8Xn_sd1wjwD-Ivry9U3adNTAZdxNOa5htnKYJBZ4zffw/file [following]\n",
            "--2021-02-21 14:42:51--  https://ucc0cd506fd7def7b84ce00cd1e0.dl.dropboxusercontent.com/cd/0/inline2/BJV-HLDNn4_K2LjbSQmfAKTTenb6oaY7FgclPkv2ciEXBNz7OPTwH8tb6iHhXMELP48fZy74I00Jdxbe89TTN1xc5jvd0bcjxZV6kl6COUUUnE_iZT3oUGbOlT3UHFg7awZ3Q69ioKsMt5BrnLb1MCybWQz53hZaC1kMD1BPoaly3jaMOMWe-QNoTpdrlw4b_ynp4bEuBZYIgNogJjfbkuZonXeqQXasUCdJ9tZgrbiXsL2P7TFinN6EwCsD-AC5Oez-QRDA2K2fGFC7s4JJOLwSfZtwIKm-lqvTWTpk5LSstM0uct4BKVRqLJphQ3lvhi8Xn_sd1wjwD-Ivry9U3adNTAZdxNOa5htnKYJBZ4zffw/file\n",
            "Reusing existing connection to ucc0cd506fd7def7b84ce00cd1e0.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 92415438 (88M) [application/zip]\n",
            "Saving to: ‘wiki.zip’\n",
            "\n",
            "wiki.zip            100%[===================>]  88.13M  22.8MB/s    in 4.4s    \n",
            "\n",
            "2021-02-21 14:42:57 (20.0 MB/s) - ‘wiki.zip’ saved [92415438/92415438]\n",
            "\n",
            "Archive:  wiki.zip\n",
            "   creating: wiki/\n",
            "  inflating: __MACOSX/._wiki         \n",
            "  inflating: wiki/thwiki_chk.txt     \n",
            "  inflating: __MACOSX/wiki/._thwiki_chk.txt  \n",
            "Archive:  BEST-TrainingSet.zip\n",
            "   creating: BEST-TrainingSet/\n",
            "  inflating: __MACOSX/._BEST-TrainingSet  \n",
            "  inflating: BEST-TrainingSet/.DS_Store  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/._.DS_Store  \n",
            "   creating: BEST-TrainingSet/encyclopedia/\n",
            "  inflating: __MACOSX/BEST-TrainingSet/._encyclopedia  \n",
            "   creating: BEST-TrainingSet/novel/\n",
            "  inflating: __MACOSX/BEST-TrainingSet/._novel  \n",
            "   creating: BEST-TrainingSet/news/\n",
            "  inflating: __MACOSX/BEST-TrainingSet/._news  \n",
            "   creating: BEST-TrainingSet/article/\n",
            "  inflating: __MACOSX/BEST-TrainingSet/._article  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00031.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00031.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00025.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00025.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00019.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00019.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00018.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00018.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00024.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00024.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00030.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00030.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00026.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00026.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00032.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00032.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00033.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00033.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00027.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00027.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00023.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00023.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00037.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00037.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00036.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00036.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00022.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00022.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00008.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00008.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00034.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00034.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00020.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00020.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00021.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00021.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00035.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00035.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00009.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00009.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00052.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00052.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00046.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00046.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00091.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00091.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00085.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00085.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00084.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00084.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00090.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00090.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00047.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00047.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00053.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00053.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00045.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00045.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00051.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00051.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00079.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00079.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00086.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00086.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00092.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00092.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00093.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00093.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00087.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00087.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00078.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00078.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00050.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00050.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00044.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00044.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00108.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00108.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00068.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00068.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00040.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00040.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00054.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00054.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00083.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00083.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00097.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00097.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00096.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00096.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00082.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00082.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00055.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00055.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00041.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00041.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00069.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00069.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00057.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00057.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00043.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00043.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00094.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00094.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00080.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00080.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00081.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00081.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00095.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00095.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00042.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00042.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00056.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00056.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00107.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00107.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00073.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00073.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00067.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00067.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00098.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00098.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00099.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00099.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00066.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00066.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00072.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00072.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00106.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00106.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00104.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00104.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00064.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00064.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00070.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00070.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00058.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00058.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00059.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00059.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00071.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00071.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00065.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00065.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00105.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00105.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00101.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00101.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00049.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00049.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00061.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00061.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00075.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00075.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00074.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00074.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00060.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00060.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00048.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00048.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00100.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00100.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00102.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00102.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00076.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00076.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00062.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00062.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00089.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00089.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00088.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00088.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00063.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00063.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00077.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00077.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00103.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00103.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00010.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00010.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00004.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00004.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00038.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00038.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00039.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00039.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00005.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00005.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00011.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00011.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00007.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00007.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00013.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00013.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00012.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00012.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00006.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00006.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00002.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00002.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00016.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00016.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00017.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00017.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00003.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00003.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00029.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00029.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00015.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00015.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00001.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00001.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00014.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00014.txt  \n",
            "  inflating: BEST-TrainingSet/encyclopedia/encyclopedia_00028.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/encyclopedia/._encyclopedia_00028.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00089.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00089.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00076.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00076.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00062.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00062.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00102.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00102.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00103.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00103.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00063.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00063.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00077.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00077.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00088.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00088.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00061.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00061.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00075.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00075.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00049.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00049.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00101.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00101.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00100.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00100.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00048.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00048.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00074.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00074.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00060.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00060.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00058.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00058.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00064.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00064.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00070.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00070.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00104.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00104.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00105.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00105.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00071.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00071.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00065.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00065.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00059.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00059.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00098.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00098.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00073.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00073.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00067.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00067.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00107.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00107.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00106.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00106.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00066.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00066.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00072.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00072.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00099.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00099.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00015.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00015.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00001.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00001.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00029.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00029.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00028.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00028.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00014.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00014.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00002.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00002.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00016.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00016.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00017.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00017.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00003.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00003.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00007.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00007.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00013.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00013.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00012.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00012.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00006.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00006.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00038.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00038.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00010.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00010.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00004.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00004.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00005.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00005.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00011.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00011.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00039.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00039.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00034.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00034.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00020.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00020.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00008.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00008.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00009.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00009.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00021.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00021.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00035.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00035.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00023.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00023.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00037.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00037.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00036.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00036.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00022.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00022.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00026.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00026.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00032.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00032.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00033.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00033.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00027.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00027.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00019.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00019.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00031.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00031.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00025.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00025.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00024.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00024.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00030.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00030.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00018.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00018.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00094.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00094.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00080.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00080.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00057.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00057.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00043.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00043.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00042.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00042.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00056.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00056.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00081.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00081.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00095.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00095.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00083.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00083.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00097.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00097.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00040.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00040.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00054.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00054.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00068.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00068.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00069.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00069.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00055.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00055.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00041.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00041.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00096.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00096.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00082.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00082.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00086.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00086.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00092.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00092.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00079.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00079.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00045.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00045.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00051.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00051.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00050.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00050.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00044.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00044.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00078.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00078.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00093.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00093.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00087.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00087.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00091.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00091.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00085.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00085.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00052.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00052.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00046.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00046.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00047.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00047.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00053.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00053.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00084.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00084.txt  \n",
            "  inflating: BEST-TrainingSet/novel/novel_00090.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/novel/._novel_00090.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00073.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00073.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00067.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00067.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00066.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00066.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00072.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00072.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00058.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00058.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00064.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00064.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00070.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00070.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00071.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00071.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00065.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00065.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00059.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00059.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00061.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00061.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00075.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00075.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00049.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00049.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00048.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00048.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00074.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00074.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00060.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00060.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00076.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00076.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00062.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00062.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00089.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00089.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00088.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00088.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00063.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00063.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00077.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00077.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00038.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00038.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00010.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00010.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00004.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00004.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00005.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00005.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00011.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00011.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00039.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00039.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00007.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00007.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00013.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00013.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00012.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00012.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00006.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00006.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00002.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00002.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00016.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00016.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00017.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00017.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00003.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00003.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00015.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00015.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00001.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00001.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00029.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00029.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00028.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00028.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00014.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00014.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00019.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00019.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00031.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00031.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00025.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00025.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00024.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00024.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00030.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00030.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00018.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00018.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00026.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00026.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00032.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00032.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00033.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00033.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00027.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00027.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00023.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00023.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00037.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00037.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00036.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00036.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00022.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00022.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00034.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00034.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00020.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00020.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00008.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00008.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00009.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00009.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00021.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00021.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00035.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00035.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00052.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00052.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00046.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00046.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00091.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00091.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00085.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00085.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00084.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00084.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00090.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00090.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00047.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00047.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00053.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00053.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00079.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00079.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00045.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00045.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00051.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00051.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00086.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00086.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00092.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00092.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00093.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00093.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00087.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00087.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00050.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00050.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00044.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00044.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00078.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00078.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00040.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00040.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00054.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00054.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00068.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00068.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00083.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00083.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00096.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00096.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00082.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00082.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00069.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00069.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00055.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00055.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00041.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00041.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00057.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00057.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00043.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00043.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00094.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00094.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00080.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00080.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00081.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00081.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00095.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00095.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00042.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00042.txt  \n",
            "  inflating: BEST-TrainingSet/news/news_00056.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/news/._news_00056.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00011.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00011.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00005.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00005.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00039.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00039.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00165.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00165.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00171.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00171.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00159.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00159.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00158.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00158.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00170.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00170.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00164.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00164.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00038.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00038.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00004.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00004.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00010.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00010.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00006.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00006.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00012.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00012.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00172.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00172.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00166.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00166.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00198.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00198.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00167.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00167.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00173.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00173.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00013.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00013.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00007.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00007.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00003.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00003.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00017.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00017.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00177.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00177.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00163.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00163.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00188.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00188.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00189.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00189.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00162.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00162.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00176.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00176.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00016.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00016.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00002.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00002.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00028.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00028.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00014.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00014.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00148.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00148.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00160.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00160.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00174.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00174.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00175.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00175.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00161.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00161.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00149.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00149.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00001.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00001.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00015.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00015.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00029.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00029.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00072.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00072.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00066.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00066.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00099.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00099.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00106.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00106.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00112.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00112.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00113.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00113.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00107.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00107.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00098.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00098.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00073.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00073.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00065.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00065.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00071.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00071.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00059.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00059.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00111.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00111.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00105.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00105.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00139.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00139.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00138.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00138.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00104.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00104.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00110.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00110.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00070.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00070.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00064.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00064.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00048.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00048.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00060.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00060.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00074.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00074.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00128.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00128.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00114.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00114.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00100.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00100.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00101.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00101.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00115.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00115.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00129.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00129.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00075.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00075.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00061.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00061.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00049.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00049.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00077.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00077.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00063.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00063.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00088.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00088.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00103.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00103.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00117.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00117.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00116.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00116.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00102.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00102.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00089.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00089.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00062.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00062.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00076.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00076.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00053.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00053.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00047.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00047.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00090.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00090.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00084.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00084.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00127.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00127.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00133.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00133.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00132.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00132.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00126.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00126.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00085.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00085.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00091.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00091.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00046.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00046.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00052.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00052.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00044.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00044.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00050.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00050.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00078.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00078.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00087.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00087.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00093.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00093.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00130.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00130.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00124.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00124.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00118.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00118.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00119.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00119.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00125.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00125.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00131.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00131.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00092.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00092.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00086.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00086.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00079.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00079.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00051.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00051.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00045.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00045.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00069.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00069.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00041.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00041.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00055.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00055.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00082.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00082.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00096.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00096.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00109.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00109.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00135.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00135.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00121.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00121.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00120.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00120.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00134.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00134.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00108.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00108.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00097.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00097.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00083.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00083.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00054.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00054.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00040.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00040.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00068.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00068.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00056.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00056.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00042.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00042.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00095.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00095.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00081.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00081.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00122.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00122.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00136.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00136.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00137.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00137.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00123.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00123.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00080.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00080.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00094.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00094.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00043.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00043.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00057.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00057.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00030.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00030.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00024.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00024.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00018.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00018.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00144.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00144.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00150.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00150.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00178.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00178.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00187.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00187.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00193.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00193.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00192.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00192.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00186.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00186.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00179.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00179.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00151.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00151.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00145.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00145.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00019.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00019.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00025.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00025.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00031.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00031.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00027.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00027.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00033.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00033.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00153.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00153.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00147.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00147.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00190.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00190.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00184.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00184.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00185.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00185.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00191.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00191.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00146.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00146.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00152.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00152.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00032.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00032.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00026.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00026.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00022.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00022.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00036.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00036.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00156.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00156.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00142.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00142.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00195.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00195.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00181.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00181.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00180.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00180.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00194.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00194.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00143.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00143.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00157.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00157.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00037.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00037.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00023.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00023.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00009.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00009.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00035.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00035.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00021.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00021.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00169.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00169.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00141.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00141.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00155.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00155.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00196.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00196.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00197.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00197.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00183.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00183.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00154.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00154.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00140.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00140.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00168.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00168.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00020.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00020.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00034.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00034.txt  \n",
            "  inflating: BEST-TrainingSet/article/article_00008.txt  \n",
            "  inflating: __MACOSX/BEST-TrainingSet/article/._article_00008.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0ALwvtzDZ-f"
      },
      "source": [
        "#Step 1: read the wikipedia text file\n",
        "with open(\"wiki/thwiki_chk.txt\") as f:\n",
        "    #the delimiter is one or more whitespace characters\n",
        "    input_text = re.compile(r\"\\s+\").split(f.read()) \n",
        "    #exclude an empty string from our input\n",
        "    input_text = [word for word in input_text if word != ''] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXoFAfjaDcJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415518b7-6592-4236-a1c7-6b9df2117de9"
      },
      "source": [
        "tokens = input_text\n",
        "print(tokens[:10])\n",
        "print(\"total word count:\", len(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['หน้า', 'หลัก', 'วิกิพีเดีย', 'ดำเนินการ', 'โดย', 'มูลนิธิ', 'วิกิ', 'มีเดีย', 'องค์กร', 'ไม่']\n",
            "total word count: 36349066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDVMvTRci-Xu"
      },
      "source": [
        "# Step 2: Indexing (Assign a number to each word)\n",
        "\n",
        "The code below generates an indexed dataset(each word is represented by a number), a dictionary, a reversed dictionary\n",
        "\n",
        "## <font color=''>Homework Question 1:</font>\n",
        "<font color=''>“UNK” is often used to represent an unknown word (a word which does not exist in your dictionary/training set). You can also represent a rare word with this token as well.  How do you define a rare word in your program? Explain in your own words and capture the screenshot of your code segment that is a part of this process</font>\n",
        "\n",
        " + <font color=''>edit or replace create_index with your own code to set a threshold for rare words and replace them with \"UNK\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6NP7nQGi-Xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ccce31-c4a4-4b23-e367-681e0eb09ee3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "word_count_global = None\n",
        "#step 2:Build dictionary and build a dataset(replace each word with its index)\n",
        "def create_index(input_text, min_thres_unk = 0, max_word_count = None):\n",
        "    global word_count_global\n",
        "    # TODO#1 : edit or replace this function\n",
        "    words = [word for word in input_text ]\n",
        "    word_count = list()\n",
        "\n",
        "    #use set and len to get the number of unique words\n",
        "    word_count.extend(collections.Counter(words).most_common(len(set(words))))\n",
        "    #include a token for unknown word\n",
        "    word_count.append((\"UNK\",0))\n",
        "    word_count_global = word_count\n",
        "\n",
        "    #print out 10 most frequent words\n",
        "    print(word_count[:10])\n",
        "\n",
        "    dictionary = dict()\n",
        "    dictionary[\"for_keras_zero_padding\"] = 0\n",
        "    for word, count in word_count:\n",
        "      if count > min_thres_unk or word == 'UNK':\n",
        "        dictionary[word] = len(dictionary)\n",
        "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
        "    data = list()\n",
        "    for word in input_text:\n",
        "      if word not in dictionary:\n",
        "        data.append(dictionary['UNK'])\n",
        "      else:\n",
        "        data.append(dictionary[word])\n",
        "\n",
        "    return data,dictionary, reverse_dictionary\n",
        "\n",
        "# call method with min_thres_unk=1ß\n",
        "dataset, dictionary, reverse_dictionary = create_index(tokens, 3)\n",
        "print(len(dataset))\n",
        "print(len(dictionary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ที่', 950006), ('ใน', 897329), ('เป็น', 726847), ('และ', 668116), ('การ', 619128), ('มี', 536738), ('ของ', 532237), ('ได้', 508117), (')', 359576), ('\"', 357830)]\n",
            "36349066\n",
            "153544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1AHl_hclFEP"
      },
      "source": [
        "## Explain\r\n",
        "I plot frequency of words to see what threshold shall I cut<br>\r\n",
        "Here, I chose `threshold 3` 78.0% (of words)<br>\r\n",
        "because after this number of words increase by only 1 percent which, to me, is not significant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-Qnsaognfwql",
        "outputId": "62542feb-1345-4be1-9097-2e3971a6bf6f"
      },
      "source": [
        "bins = plt.hist([c for w,c in word_count_global], range(0,20))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUaRjN5YhmPU",
        "outputId": "5318e7ef-8b83-490e-ffc7-5b5aa1de1555"
      },
      "source": [
        "N = 701356\r\n",
        "for i in range(1,20):\r\n",
        "  n = sum(bins[0][1:i])\r\n",
        "  print('threshold', i-1, n, f'{10000 * n / N // 100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "threshold 0 0 0.0%\n",
            "threshold 1 406192.0 57.0%\n",
            "threshold 2 503531.0 71.0%\n",
            "threshold 3 547812.0 78.0%\n",
            "threshold 4 574133.0 81.0%\n",
            "threshold 5 591453.0 84.0%\n",
            "threshold 6 604487.0 86.0%\n",
            "threshold 7 614252.0 87.0%\n",
            "threshold 8 621916.0 88.0%\n",
            "threshold 9 628181.0 89.0%\n",
            "threshold 10 633380.0 90.0%\n",
            "threshold 11 637842.0 90.0%\n",
            "threshold 12 641602.0 91.0%\n",
            "threshold 13 644887.0 91.0%\n",
            "threshold 14 647841.0 92.0%\n",
            "threshold 15 650431.0 92.0%\n",
            "threshold 16 652804.0 93.0%\n",
            "threshold 17 654832.0 93.0%\n",
            "threshold 18 658550.0 93.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fotaYMgi-Xz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6f4160-83e4-4b5c-f2ad-a0fb8e622607"
      },
      "source": [
        "print(\"output sample (dataset):\",dataset[:10])\n",
        "print(\"output sample (dictionary):\",{k: dictionary[k] for k in list(dictionary)[:10]})\n",
        "print(\"output sample (reverse dictionary):\",{k: reverse_dictionary[k] for k in list(reverse_dictionary)[:10]})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output sample (dataset): [229, 208, 2453, 573, 15, 1829, 7149, 3124, 681, 24]\n",
            "output sample (dictionary): {'for_keras_zero_padding': 0, 'ที่': 1, 'ใน': 2, 'เป็น': 3, 'และ': 4, 'การ': 5, 'มี': 6, 'ของ': 7, 'ได้': 8, ')': 9}\n",
            "output sample (reverse dictionary): {0: 'for_keras_zero_padding', 1: 'ที่', 2: 'ใน', 3: 'เป็น', 4: 'และ', 5: 'การ', 6: 'มี', 7: 'ของ', 8: 'ได้', 9: ')'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HutTzPO7i-X3"
      },
      "source": [
        "# Step3: Create skip-grams (inputs for your model)\n",
        "Keras has a skipgrams-generator, the cell below shows us how it generates skipgrams \n",
        "\n",
        "## <font color=''>Homework Question 2:</font>\n",
        "<font color=''>The negative samples are sampled from sampling_table.  Look through Keras source code to find out how they sample negative samples. Discuss the sampling technique taught in class and compare it to the Keras source code.</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwYFRO3YGryQ"
      },
      "source": [
        "<font color=''>Q2: PUT YOUR ANSER HERE!!!</font><br>\r\n",
        "Keras tries to decrease probabilty of words of high frequency, while in the class, we try to increase that of words of low frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C520WnI0i-X4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02629e8a-f4a6-4398-b59c-36ec0e3a825a"
      },
      "source": [
        "# Step 3: Create data samples\n",
        "vocab_size = len(dictionary)\n",
        "skip_window = 1       # How many words to consider left and right.\n",
        "\n",
        "# TODO#2 check out keras source code and find out how their sampling technique works. Describe it in your own words.\n",
        "sample_set= dataset[:10]\n",
        "sampling_table = sequence.make_sampling_table(vocab_size)\n",
        "couples, labels = skipgrams(sample_set, vocab_size, window_size=skip_window, sampling_table=sampling_table)\n",
        "word_target, word_context = zip(*couples)\n",
        "word_target = np.array(word_target, dtype=\"int32\")\n",
        "word_context = np.array(word_context, dtype=\"int32\")\n",
        "\n",
        "print(couples, labels)\n",
        "\n",
        "for i in range(8):\n",
        "  print(reverse_dictionary[couples[i][0]],reverse_dictionary[couples[i][1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[208, 41854], [208, 2453], [2453, 573], [208, 117758], [24, 681], [2453, 208], [3124, 72927], [2453, 57788], [24, 1704], [208, 229], [3124, 681], [3124, 7149], [3124, 142854], [2453, 109975]] [0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "หลัก ซัมเมอร์ส\n",
            "หลัก วิกิพีเดีย\n",
            "วิกิพีเดีย ดำเนินการ\n",
            "หลัก คอนเวอร์เตอร์\n",
            "ไม่ องค์กร\n",
            "วิกิพีเดีย หลัก\n",
            "มีเดีย เหรียญศาร\n",
            "วิกิพีเดีย แวร์ซาย\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6UL0FhEi-X6"
      },
      "source": [
        "# Step 4: create the skip-gram model\n",
        "## <font color=''>Homework Question 3:</font>\n",
        " <font color=''>Q3:  In your own words, discuss why Sigmoid is chosen as the activation function in the  skip-gram model.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oQLGkkuHG7o"
      },
      "source": [
        "<font color='red'>Q3: PUT YOUR ANSER HERE!!!</font>\r\n",
        " <br>\r\n",
        " First of all, it is memory friendly. No matter how we calculate cosine similarity of a pair of words. The output is only one number instead of N-dim vector.<br>\r\n",
        " In addition, loss function uses log which make much more sense with [0,1] for probability rather than relu [0,inf) or tanh [-1,1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq7Eh9pXi-X7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a029b7ab-a50d-44f6-9cfd-4d85b175b5ce"
      },
      "source": [
        "#reference: https://github.com/nzw0301/keras-examples/blob/master/Skip-gram-with-NS.ipynb\n",
        "dim_embedddings = 32\n",
        "V= len(dictionary)\n",
        "\n",
        "#step1: select the embedding of the target word from W\n",
        "w_inputs = Input(shape=(1, ), dtype='int32')\n",
        "w = Embedding(V+1, dim_embedddings)(w_inputs)\n",
        "\n",
        "#step2: select the embedding of the context word from C\n",
        "c_inputs = Input(shape=(1, ), dtype='int32')\n",
        "c  = Embedding(V+1, dim_embedddings)(c_inputs)\n",
        "\n",
        "#step3: compute the dot product:c_k*v_j\n",
        "o = Dot(axes=2)([w, c])\n",
        "o = Reshape((1,), input_shape=(1, 1))(o)\n",
        "\n",
        "#step4: normailize dot products into probability\n",
        "o = Activation('sigmoid')(o)\n",
        "#TO DO#4 Question: Why sigmoid?\n",
        "\n",
        "SkipGram = Model(inputs=[w_inputs, c_inputs], outputs=o)\n",
        "SkipGram.summary()\n",
        "opt=Adam(lr=0.01)\n",
        "SkipGram.compile(loss='binary_crossentropy', optimizer=opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1, 32)        4913440     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 32)        4913440     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 1)         0           embedding[0][0]                  \n",
            "                                                                 embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1)            0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1)            0           reshape[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 9,826,880\n",
            "Trainable params: 9,826,880\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSBL1EXFgCo8",
        "outputId": "1634a9cb-df68-4016-b567-a1a632a4e3af"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgR5p_h1i-X9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f06fb9-78f3-4e40-b40d-c4258f1af7fd"
      },
      "source": [
        "# you don't have to spend too much time training for your homework, you are allowed to do it on a smaller corpus\n",
        "# currently the dataset is 1/20 of the full text file.\n",
        "multiplier = 100000\n",
        "for _ in range(2):\n",
        "    prev_i=0\n",
        "    #it is likely that your GPU won't be able to handle large input\n",
        "    #just do it 100000 words at a time\n",
        "    for i in range(len(dataset)//multiplier):\n",
        "        #generate skipgrams\n",
        "        data, labels = skipgrams(sequence=dataset[prev_i*multiplier:(i*multiplier)+multiplier], vocabulary_size=V, window_size=2, negative_samples=4.)\n",
        "        x = [np.array(x) for x in zip(*data)]\n",
        "        y = np.array(labels, dtype=np.int32)\n",
        "        if x:\n",
        "            loss = SkipGram.train_on_batch(x, y)\n",
        "            SkipGram.save_weights(f'/content/drive/MyDrive/hw5-skipgram/my_skipgram32_weights-hw-{i*multiplier}-{loss}.h5')\n",
        "        prev_i = i \n",
        "        print(loss,i*multiplier)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931530237197876 0\n",
            "0.6931214332580566 100000\n",
            "0.6930861473083496 200000\n",
            "0.6930124759674072 300000\n",
            "0.6928961277008057 400000\n",
            "0.6927148699760437 500000\n",
            "0.6924630403518677 600000\n",
            "0.6921004056930542 700000\n",
            "0.691530168056488 800000\n",
            "0.6908166408538818 900000\n",
            "0.6899302005767822 1000000\n",
            "0.6886997222900391 1100000\n",
            "0.6873592734336853 1200000\n",
            "0.6853577494621277 1300000\n",
            "0.683154821395874 1400000\n",
            "0.6809923052787781 1500000\n",
            "0.6776577234268188 1600000\n",
            "0.6737194061279297 1700000\n",
            "0.6692689657211304 1800000\n",
            "0.6647663116455078 1900000\n",
            "0.6600084900856018 2000000\n",
            "0.6530169248580933 2100000\n",
            "0.645172655582428 2200000\n",
            "0.6374605894088745 2300000\n",
            "0.628936231136322 2400000\n",
            "0.6202719807624817 2500000\n",
            "0.6108173131942749 2600000\n",
            "0.6020578145980835 2700000\n",
            "0.591934323310852 2800000\n",
            "0.578183650970459 2900000\n",
            "0.5638103485107422 3000000\n",
            "0.5502883195877075 3100000\n",
            "0.5370844602584839 3200000\n",
            "0.5254123210906982 3300000\n",
            "0.5098598003387451 3400000\n",
            "0.49096444249153137 3500000\n",
            "0.4756113588809967 3600000\n",
            "0.4601725935935974 3700000\n",
            "0.4440819025039673 3800000\n",
            "0.4272759258747101 3900000\n",
            "0.4090021848678589 4000000\n",
            "0.3904587924480438 4100000\n",
            "0.37969639897346497 4200000\n",
            "0.376677930355072 4300000\n",
            "0.3571409285068512 4400000\n",
            "0.33185631036758423 4500000\n",
            "0.3235989809036255 4600000\n",
            "0.31041231751441956 4700000\n",
            "0.293535977602005 4800000\n",
            "0.2814064621925354 4900000\n",
            "0.2687258720397949 5000000\n",
            "0.26253628730773926 5100000\n",
            "0.2613184154033661 5200000\n",
            "0.2501433789730072 5300000\n",
            "0.2380475252866745 5400000\n",
            "0.23104272782802582 5500000\n",
            "0.22947844862937927 5600000\n",
            "0.22677022218704224 5700000\n",
            "0.21592868864536285 5800000\n",
            "0.20787546038627625 5900000\n",
            "0.20551131665706635 6000000\n",
            "0.20396390557289124 6100000\n",
            "0.19759976863861084 6200000\n",
            "0.19814936816692352 6300000\n",
            "0.19642366468906403 6400000\n",
            "0.1872558295726776 6500000\n",
            "0.186908558011055 6600000\n",
            "0.1904391497373581 6700000\n",
            "0.18519656360149384 6800000\n",
            "0.18239286541938782 6900000\n",
            "0.180092453956604 7000000\n",
            "0.17799727618694305 7100000\n",
            "0.18102319538593292 7200000\n",
            "0.18308237195014954 7300000\n",
            "0.1788596510887146 7400000\n",
            "0.17326965928077698 7500000\n",
            "0.17533622682094574 7600000\n",
            "0.17724928259849548 7700000\n",
            "0.17167824506759644 7800000\n",
            "0.1668933480978012 7900000\n",
            "0.16857190430164337 8000000\n",
            "0.1696702390909195 8100000\n",
            "0.1656225174665451 8200000\n",
            "0.1662072092294693 8300000\n",
            "0.17313669621944427 8400000\n",
            "0.17227932810783386 8500000\n",
            "0.16776517033576965 8600000\n",
            "0.16657596826553345 8700000\n",
            "0.16734224557876587 8800000\n",
            "0.17057599127292633 8900000\n",
            "0.16842961311340332 9000000\n",
            "0.16317154467105865 9100000\n",
            "0.16247791051864624 9200000\n",
            "0.1656848043203354 9300000\n",
            "0.16469340026378632 9400000\n",
            "0.16786691546440125 9500000\n",
            "0.16684362292289734 9600000\n",
            "0.15842722356319427 9700000\n",
            "0.16260063648223877 9800000\n",
            "0.16026657819747925 9900000\n",
            "0.15366622805595398 10000000\n",
            "0.1615290492773056 10100000\n",
            "0.16707898676395416 10200000\n",
            "0.16837003827095032 10300000\n",
            "0.16772809624671936 10400000\n",
            "0.1615631878376007 10500000\n",
            "0.16416913270950317 10600000\n",
            "0.1673937290906906 10700000\n",
            "0.1589277982711792 10800000\n",
            "0.15769736468791962 10900000\n",
            "0.1584479659795761 11000000\n",
            "0.15195080637931824 11100000\n",
            "0.1507454514503479 11200000\n",
            "0.15327082574367523 11300000\n",
            "0.1534891128540039 11400000\n",
            "0.15197095274925232 11500000\n",
            "0.1500801146030426 11600000\n",
            "0.14916782081127167 11700000\n",
            "0.15197496116161346 11800000\n",
            "0.15890613198280334 11900000\n",
            "0.15844164788722992 12000000\n",
            "0.1543305665254593 12100000\n",
            "0.15115152299404144 12200000\n",
            "0.15015646815299988 12300000\n",
            "0.1546829789876938 12400000\n",
            "0.1557229459285736 12500000\n",
            "0.15321528911590576 12600000\n",
            "0.1505175679922104 12700000\n",
            "0.15209649503231049 12800000\n",
            "0.15617404878139496 12900000\n",
            "0.15794384479522705 13000000\n",
            "0.15572629868984222 13100000\n",
            "0.15227296948432922 13200000\n",
            "0.15183581411838531 13300000\n",
            "0.15523992478847504 13400000\n",
            "0.16023600101470947 13500000\n",
            "0.15719948709011078 13600000\n",
            "0.1585683971643448 13700000\n",
            "0.16308178007602692 13800000\n",
            "0.1599757820367813 13900000\n",
            "0.15633417665958405 14000000\n",
            "0.15401718020439148 14100000\n",
            "0.15446747839450836 14200000\n",
            "0.15873932838439941 14300000\n",
            "0.1587718427181244 14400000\n",
            "0.1526406705379486 14500000\n",
            "0.15657450258731842 14600000\n",
            "0.1562623530626297 14700000\n",
            "0.14959076046943665 14800000\n",
            "0.1496637761592865 14900000\n",
            "0.14940834045410156 15000000\n",
            "0.15372900664806366 15100000\n",
            "0.1590094417333603 15200000\n",
            "0.1575734168291092 15300000\n",
            "0.15265321731567383 15400000\n",
            "0.14836375415325165 15500000\n",
            "0.14758941531181335 15600000\n",
            "0.14824604988098145 15700000\n",
            "0.15004028379917145 15800000\n",
            "0.15181244909763336 15900000\n",
            "0.1574752926826477 16000000\n",
            "0.15794171392917633 16100000\n",
            "0.15031565725803375 16200000\n",
            "0.14487352967262268 16300000\n",
            "0.15391945838928223 16400000\n",
            "0.1546127200126648 16500000\n",
            "0.1478259563446045 16600000\n",
            "0.14863167703151703 16700000\n",
            "0.14581653475761414 16800000\n",
            "0.13965800404548645 16900000\n",
            "0.14275547862052917 17000000\n",
            "0.1466832011938095 17100000\n",
            "0.14781107008457184 17200000\n",
            "0.15024074912071228 17300000\n",
            "0.15216198563575745 17400000\n",
            "0.1562947928905487 17500000\n",
            "0.15673860907554626 17600000\n",
            "0.15023215115070343 17700000\n",
            "0.14537550508975983 17800000\n",
            "0.14866358041763306 17900000\n",
            "0.14750881493091583 18000000\n",
            "0.1465543508529663 18100000\n",
            "0.1446087807416916 18200000\n",
            "0.13914702832698822 18300000\n",
            "0.14331084489822388 18400000\n",
            "0.14571262896060944 18500000\n",
            "0.14335575699806213 18600000\n",
            "0.14484448730945587 18700000\n",
            "0.1430504471063614 18800000\n",
            "0.14092624187469482 18900000\n",
            "0.14178402721881866 19000000\n",
            "0.14694331586360931 19100000\n",
            "0.14752520620822906 19200000\n",
            "0.1428128182888031 19300000\n",
            "0.14252234995365143 19400000\n",
            "0.14073391258716583 19500000\n",
            "0.1388378143310547 19600000\n",
            "0.14123938977718353 19700000\n",
            "0.14010018110275269 19800000\n",
            "0.14492635428905487 19900000\n",
            "0.14722506701946259 20000000\n",
            "0.1428530216217041 20100000\n",
            "0.14660342037677765 20200000\n",
            "0.14629189670085907 20300000\n",
            "0.14440928399562836 20400000\n",
            "0.144619420170784 20500000\n",
            "0.1428563892841339 20600000\n",
            "0.14562079310417175 20700000\n",
            "0.14586620032787323 20800000\n",
            "0.14197160303592682 20900000\n",
            "0.14046093821525574 21000000\n",
            "0.13513779640197754 21100000\n",
            "0.13342075049877167 21200000\n",
            "0.13794074952602386 21300000\n",
            "0.13560795783996582 21400000\n",
            "0.1349196881055832 21500000\n",
            "0.13864314556121826 21600000\n",
            "0.1374512016773224 21700000\n",
            "0.13545075058937073 21800000\n",
            "0.1378200650215149 21900000\n",
            "0.13008007407188416 22000000\n",
            "0.12636107206344604 22100000\n",
            "0.13849042356014252 22200000\n",
            "0.14644545316696167 22300000\n",
            "0.14150962233543396 22400000\n",
            "0.13789746165275574 22500000\n",
            "0.13637691736221313 22600000\n",
            "0.13263258337974548 22700000\n",
            "0.13463345170021057 22800000\n",
            "0.13900138437747955 22900000\n",
            "0.14330990612506866 23000000\n",
            "0.1431213766336441 23100000\n",
            "0.13899587094783783 23200000\n",
            "0.13849768042564392 23300000\n",
            "0.1361093968153 23400000\n",
            "0.13615800440311432 23500000\n",
            "0.1391058713197708 23600000\n",
            "0.13468903303146362 23700000\n",
            "0.13217414915561676 23800000\n",
            "0.13386991620063782 23900000\n",
            "0.13691550493240356 24000000\n",
            "0.1347872018814087 24100000\n",
            "0.13375291228294373 24200000\n",
            "0.13403694331645966 24300000\n",
            "0.13203075528144836 24400000\n",
            "0.12880131602287292 24500000\n",
            "0.12821120023727417 24600000\n",
            "0.13249164819717407 24700000\n",
            "0.13623499870300293 24800000\n",
            "0.13681219518184662 24900000\n",
            "0.13511183857917786 25000000\n",
            "0.1337542086839676 25100000\n",
            "0.1333407759666443 25200000\n",
            "0.13491278886795044 25300000\n",
            "0.1353936791419983 25400000\n",
            "0.135078564286232 25500000\n",
            "0.13506093621253967 25600000\n",
            "0.13159002363681793 25700000\n",
            "0.12941350042819977 25800000\n",
            "0.1315840780735016 25900000\n",
            "0.13198505342006683 26000000\n",
            "0.13444077968597412 26100000\n",
            "0.13898448646068573 26200000\n",
            "0.1412012279033661 26300000\n",
            "0.14097607135772705 26400000\n",
            "0.13884153962135315 26500000\n",
            "0.1371353566646576 26600000\n",
            "0.1342996507883072 26700000\n",
            "0.1343284696340561 26800000\n",
            "0.133119136095047 26900000\n",
            "0.1287962943315506 27000000\n",
            "0.1318371295928955 27100000\n",
            "0.13577991724014282 27200000\n",
            "0.13103803992271423 27300000\n",
            "0.13090991973876953 27400000\n",
            "0.13723504543304443 27500000\n",
            "0.13116049766540527 27600000\n",
            "0.13031840324401855 27700000\n",
            "0.13794177770614624 27800000\n",
            "0.1398763507604599 27900000\n",
            "0.13726820051670074 28000000\n",
            "0.13172347843647003 28100000\n",
            "0.1309138536453247 28200000\n",
            "0.12928225100040436 28300000\n",
            "0.1299198418855667 28400000\n",
            "0.13200491666793823 28500000\n",
            "0.13140973448753357 28600000\n",
            "0.13365764915943146 28700000\n",
            "0.1380327045917511 28800000\n",
            "0.14188028872013092 28900000\n",
            "0.13846777379512787 29000000\n",
            "0.13384774327278137 29100000\n",
            "0.13722242414951324 29200000\n",
            "0.13895709812641144 29300000\n",
            "0.13919849693775177 29400000\n",
            "0.13765762746334076 29500000\n",
            "0.13432000577449799 29600000\n",
            "0.14012272655963898 29700000\n",
            "0.14436854422092438 29800000\n",
            "0.13856159150600433 29900000\n",
            "0.1404826045036316 30000000\n",
            "0.14160804450511932 30100000\n",
            "0.1367182433605194 30200000\n",
            "0.1386772096157074 30300000\n",
            "0.14080944657325745 30400000\n",
            "0.1356494426727295 30500000\n",
            "0.13129831850528717 30600000\n",
            "0.13274003565311432 30700000\n",
            "0.13434596359729767 30800000\n",
            "0.13425174355506897 30900000\n",
            "0.13396622240543365 31000000\n",
            "0.13252872228622437 31100000\n",
            "0.13300666213035583 31200000\n",
            "0.13759100437164307 31300000\n",
            "0.13596147298812866 31400000\n",
            "0.1330978125333786 31500000\n",
            "0.1388663947582245 31600000\n",
            "0.13939625024795532 31700000\n",
            "0.13820093870162964 31800000\n",
            "0.1356297880411148 31900000\n",
            "0.1315779834985733 32000000\n",
            "0.13045327365398407 32100000\n",
            "0.1359603852033615 32200000\n",
            "0.13903798162937164 32300000\n",
            "0.13196878135204315 32400000\n",
            "0.1348162442445755 32500000\n",
            "0.1368304044008255 32600000\n",
            "0.13080757856369019 32700000\n",
            "0.13316339254379272 32800000\n",
            "0.13390739262104034 32900000\n",
            "0.12816248834133148 33000000\n",
            "0.12715397775173187 33100000\n",
            "0.1272757202386856 33200000\n",
            "0.130482479929924 33300000\n",
            "0.13299518823623657 33400000\n",
            "0.13328349590301514 33500000\n",
            "0.12866581976413727 33600000\n",
            "0.1240607276558876 33700000\n",
            "0.12810049951076508 33800000\n",
            "0.13447827100753784 33900000\n",
            "0.13520397245883942 34000000\n",
            "0.13484139740467072 34100000\n",
            "0.13436271250247955 34200000\n",
            "0.13641037046909332 34300000\n",
            "0.13738228380680084 34400000\n",
            "0.13378925621509552 34500000\n",
            "0.12561292946338654 34600000\n",
            "0.12620745599269867 34700000\n",
            "0.12831732630729675 34800000\n",
            "0.12464457005262375 34900000\n",
            "0.12533558905124664 35000000\n",
            "0.12452743202447891 35100000\n",
            "0.124265655875206 35200000\n",
            "0.1258786916732788 35300000\n",
            "0.12956379354000092 35400000\n",
            "0.13532128930091858 35500000\n",
            "0.13852480053901672 35600000\n",
            "0.13009798526763916 35700000\n",
            "0.1253158152103424 35800000\n",
            "0.12842987477779388 35900000\n",
            "0.1250647008419037 36000000\n",
            "0.12239323556423187 36100000\n",
            "0.1279146671295166 36200000\n",
            "0.11500293016433716 0\n",
            "0.11871139705181122 100000\n",
            "0.11724771559238434 200000\n",
            "0.10992907732725143 300000\n",
            "0.1102200374007225 400000\n",
            "0.11298765987157822 500000\n",
            "0.10982363671064377 600000\n",
            "0.11111265420913696 700000\n",
            "0.11525403708219528 800000\n",
            "0.12089486420154572 900000\n",
            "0.12088270485401154 1000000\n",
            "0.11426243185997009 1100000\n",
            "0.11901162564754486 1200000\n",
            "0.11535757035017014 1300000\n",
            "0.11647564172744751 1400000\n",
            "0.12515252828598022 1500000\n",
            "0.12353432923555374 1600000\n",
            "0.12188414484262466 1700000\n",
            "0.12102247029542923 1800000\n",
            "0.1216791570186615 1900000\n",
            "0.12407748401165009 2000000\n",
            "0.11841236799955368 2100000\n",
            "0.11412537097930908 2200000\n",
            "0.1163180023431778 2300000\n",
            "0.11664127558469772 2400000\n",
            "0.11983536183834076 2500000\n",
            "0.11927967518568039 2600000\n",
            "0.12776002287864685 2700000\n",
            "0.1353580802679062 2800000\n",
            "0.13081242144107819 2900000\n",
            "0.12427756935358047 3000000\n",
            "0.12413899600505829 3100000\n",
            "0.12989424169063568 3200000\n",
            "0.133154034614563 3300000\n",
            "0.13230086863040924 3400000\n",
            "0.128848597407341 3500000\n",
            "0.12758606672286987 3600000\n",
            "0.12567546963691711 3700000\n",
            "0.12398044764995575 3800000\n",
            "0.12328020483255386 3900000\n",
            "0.12203842401504517 4000000\n",
            "0.12146522849798203 4100000\n",
            "0.1292831152677536 4200000\n",
            "0.14013183116912842 4300000\n",
            "0.13209006190299988 4400000\n",
            "0.12127505242824554 4500000\n",
            "0.12945060431957245 4600000\n",
            "0.12999695539474487 4700000\n",
            "0.12333827465772629 4800000\n",
            "0.12326148897409439 4900000\n",
            "0.1225787103176117 5000000\n",
            "0.12624689936637878 5100000\n",
            "0.13177497684955597 5200000\n",
            "0.12745605409145355 5300000\n",
            "0.1246909648180008 5400000\n",
            "0.12463676184415817 5500000\n",
            "0.1279027760028839 5600000\n",
            "0.13055410981178284 5700000\n",
            "0.1259484440088272 5800000\n",
            "0.12266258895397186 5900000\n",
            "0.12426583468914032 6000000\n",
            "0.1258019655942917 6100000\n",
            "0.12393803894519806 6200000\n",
            "0.12485910207033157 6300000\n",
            "0.1261323243379593 6400000\n",
            "0.12179254740476608 6500000\n",
            "0.12336181104183197 6600000\n",
            "0.12690435349941254 6700000\n",
            "0.1242440715432167 6800000\n",
            "0.12384095042943954 6900000\n",
            "0.12314154207706451 7000000\n",
            "0.12249917536973953 7100000\n",
            "0.12669673562049866 7200000\n",
            "0.12885712087154388 7300000\n",
            "0.12659133970737457 7400000\n",
            "0.12395621091127396 7500000\n",
            "0.12596020102500916 7600000\n",
            "0.12818557024002075 7700000\n",
            "0.12537138164043427 7800000\n",
            "0.1217833012342453 7900000\n",
            "0.12341973930597305 8000000\n",
            "0.12572312355041504 8100000\n",
            "0.12324032187461853 8200000\n",
            "0.12403509020805359 8300000\n",
            "0.12660355865955353 8400000\n",
            "0.1263272613286972 8500000\n",
            "0.12603358924388885 8600000\n",
            "0.12480859458446503 8700000\n",
            "0.1259297877550125 8800000\n",
            "0.1288892775774002 8900000\n",
            "0.12774662673473358 9000000\n",
            "0.12375405430793762 9100000\n",
            "0.12349755316972733 9200000\n",
            "0.12686680257320404 9300000\n",
            "0.12658627331256866 9400000\n",
            "0.12935087084770203 9500000\n",
            "0.1294364184141159 9600000\n",
            "0.12296561151742935 9700000\n",
            "0.12561456859111786 9800000\n",
            "0.12488802522420883 9900000\n",
            "0.120881088078022 10000000\n",
            "0.12673786282539368 10100000\n",
            "0.13114754855632782 10200000\n",
            "0.13266873359680176 10300000\n",
            "0.1311608850955963 10400000\n",
            "0.12698587775230408 10500000\n",
            "0.1304338574409485 10600000\n",
            "0.13263124227523804 10700000\n",
            "0.12709490954875946 10800000\n",
            "0.1259743720293045 10900000\n",
            "0.12691974639892578 11000000\n",
            "0.12270856648683548 11100000\n",
            "0.12152334302663803 11200000\n",
            "0.12317319214344025 11300000\n",
            "0.12368320673704147 11400000\n",
            "0.12272457778453827 11500000\n",
            "0.12172340601682663 11600000\n",
            "0.12082180380821228 11700000\n",
            "0.12308380007743835 11800000\n",
            "0.12833772599697113 11900000\n",
            "0.12830165028572083 12000000\n",
            "0.12560254335403442 12100000\n",
            "0.12337439507246017 12200000\n",
            "0.12299737334251404 12300000\n",
            "0.12586219608783722 12400000\n",
            "0.12700143456459045 12500000\n",
            "0.12591096758842468 12600000\n",
            "0.1236208826303482 12700000\n",
            "0.12445157766342163 12800000\n",
            "0.12696519494056702 12900000\n",
            "0.1285117268562317 13000000\n",
            "0.12787292897701263 13100000\n",
            "0.12547609210014343 13200000\n",
            "0.12548045814037323 13300000\n",
            "0.12744618952274323 13400000\n",
            "0.13007426261901855 13500000\n",
            "0.1283709704875946 13600000\n",
            "0.13023370504379272 13700000\n",
            "0.13447457551956177 13800000\n",
            "0.13305534422397614 13900000\n",
            "0.12920066714286804 14000000\n",
            "0.126264750957489 14100000\n",
            "0.1271050125360489 14200000\n",
            "0.13187140226364136 14300000\n",
            "0.13202780485153198 14400000\n",
            "0.12615172564983368 14500000\n",
            "0.127132385969162 14600000\n",
            "0.1279427856206894 14700000\n",
            "0.12492173165082932 14800000\n",
            "0.12473618239164352 14900000\n",
            "0.12402935326099396 15000000\n",
            "0.12786045670509338 15100000\n",
            "0.13260172307491302 15200000\n",
            "0.13147616386413574 15300000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY69_WFHi-X_"
      },
      "source": [
        "# SkipGram.save_weights('my_skipgram32_weights-hw.h5')\r\n",
        "SkipGram.load_weights('/content/drive/MyDrive/hw5-skipgram/my_skipgram32_weights-hw.h5')\r\n",
        "# SkipGram.load_weights('/content/drive/MyDrive/hw5-skipgram/my_skipgram32_weights-hw-33900000-0.13447827100753784.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7UD13eKki-YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03e864b-85ae-47dd-8b06-bca7dcc35d7d"
      },
      "source": [
        "#Get weight of the embedding layer\n",
        "final_embeddings=SkipGram.get_weights()[0]\n",
        "print(final_embeddings)\n",
        "print(final_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.01860917  0.01938124  0.0207364  ...  0.01218445  0.00212651\n",
            "   0.01375028]\n",
            " [-0.49981844  0.41046733 -0.59824306 ...  0.5241086  -0.5860986\n",
            "   0.5765467 ]\n",
            " [-0.50383323  0.28770196 -0.45041224 ...  0.4926264  -0.5751475\n",
            "   0.6041441 ]\n",
            " ...\n",
            " [ 0.02654959  0.02232834 -0.04700992 ...  0.01880474  0.02930037\n",
            "  -0.02829891]\n",
            " [ 0.03735652  0.00350807 -0.01710014 ...  0.04450684  0.00997959\n",
            "   0.03114747]\n",
            " [-0.46685266  0.44005847 -0.47300085 ...  0.4222149  -0.5279841\n",
            "   0.52296746]]\n",
            "(153545, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ovPmh6Ri-YC"
      },
      "source": [
        "# Step 5: Intrinsic Evaluation: Word Vector Analogies\n",
        "## <font color='blue'>Homework Question 4: </font>\n",
        "<font color='blue'> Read section 2.1 and 2.3 in this [lecture note](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes02-wordvecs2.pdf). Come up with 10 semantic analogy examples and report results produced by your word embeddings </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8rTxYaLi-YD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f872dea-9acf-46a3-ce34-8e6b5d191150"
      },
      "source": [
        "# TODO#4:Come up with 10 semantic analogy examples and report results produced by your word embeddings \n",
        "#and tell us what you observe \n",
        "\n",
        "import scipy.spatial\n",
        "s = [\n",
        "     ('แมว','หมา','สิงโต'),\n",
        "     ('ดี','ขาว','ดำ'),\n",
        "     ('โตเกียว','ญี่ปุ่น','ไทย'),\n",
        "     ('king','man', 'woman'),\n",
        "     ('ขอทาน','จน','รวย'),\n",
        "     ('เพลง','ศิลปิน','ทหาร'),\n",
        "     ('งง','โง่','ฉลาด'),\n",
        "     ('ล้น','มาก','น้อย'),\n",
        "     ('ชอบ','รัก','หลง'),\n",
        "     ('กษัตริย์','ชาย','หญิง')\n",
        "    ]\n",
        "for i in s:\n",
        "  tmp = (final_embeddings[dictionary[i[0]]]-final_embeddings[dictionary[i[1]]]+final_embeddings[dictionary[i[2]]]).reshape(1,-1)\n",
        "  all_dist = scipy.spatial.distance.cdist(final_embeddings, tmp, 'cosine').reshape(-1)\n",
        "  idx = np.argpartition(all_dist,1)[:1][0]\n",
        "  # print(reverse_dictionary[idx])\n",
        "  # idx = idx[np.argsort(all_dist[idx[:3]])]\n",
        "  # for i in idx:\n",
        "  print(i[0],'-',i[1],'+',i[2],'=',reverse_dictionary[idx])\n",
        "  print('===========')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "แมว - หมา + สิงโต = สิงโต\n",
            "===========\n",
            "เหลือง - แดง + เขียว = เหลือง\n",
            "===========\n",
            "โตเกียว - ญี่ปุ่น + ไทย = อคติ\n",
            "===========\n",
            "king - man + woman = ฮนโนจิ\n",
            "===========\n",
            "ขอทาน - จน + รวย = who\n",
            "===========\n",
            "เพลง - ศิลปิน + ทหาร = เถรวาท\n",
            "===========\n",
            "งง - โง่ + ฉลาด = ญาณ\n",
            "===========\n",
            "ล้น - มาก + น้อย = จอร์จ\n",
            "===========\n",
            "ชอบ - รัก + หลง = หลง\n",
            "===========\n",
            "กษัตริย์ - ชาย + หญิง = เอสปา\n",
            "===========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnBg4z4xSCYB"
      },
      "source": [
        "The embedding can not catch the meaning of the word that much, yet <br>\r\n",
        "`กษัตริย์ - ชาย + หญิง = เอสปา` is kinda cool, becase `เอสปา` is girl group and might be \"queen\" for their fans <br>\r\n",
        "`งง - โง่ + ฉลาด = ญาณ` is also cool, since `ญาณ` is `ปัญญา` in Buddhism<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLqG8WaNi-YE"
      },
      "source": [
        "# Step 6: Extrinsic Evaluation\n",
        "\n",
        "## <font color='blue'>Homework Question5:</font>\n",
        "<font color='blue'>\n",
        "Use the word embeddings from the skip-gram model as pre-trained weights in a classification model. Compare the result the with the same classification model that does not use the pre-trained weights. \n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBPutcxEi-YF"
      },
      "source": [
        "all_news_filepath = glob.glob('BEST-TrainingSet/news/*.txt')\n",
        "all_novel_filepath = glob.glob('BEST-TrainingSet/novel/*.txt')\n",
        "all_article_filepath = glob.glob('BEST-TrainingSet/article/*.txt')\n",
        "all_encyclopedia_filepath = glob.glob('BEST-TrainingSet/encyclopedia/*.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaX-L5n4i-YG"
      },
      "source": [
        "#preparing data for the classificaiton model\n",
        "#In your homework, we will only use the first 2000 words in each text file\n",
        "#any text file that has less than 2000 words will be padded\n",
        "#reason:just to make this homework feasible under limited time and resource\n",
        "max_length = 2000\n",
        "def word_to_index(word):\n",
        "    if word in dictionary:\n",
        "        return dictionary[word]\n",
        "    else:#if unknown\n",
        "        return dictionary[\"UNK\"]\n",
        "\n",
        "\n",
        "def prep_data():\n",
        "    input_text = list()\n",
        "    for textfile_path in [all_news_filepath, all_novel_filepath, all_article_filepath, all_encyclopedia_filepath]:\n",
        "        for input_file in textfile_path:\n",
        "            f = open(input_file,\"r\") #open file with name of \"*.txt\"\n",
        "            text = re.sub(r'\\|', ' ', f.read()) # replace separation symbol with white space           \n",
        "            text = re.sub(r'<\\W?\\w+>', '', text)# remove <NE> </NE> <AB> </AB> tags\n",
        "            text = text.split() #split() method without an argument splits on whitespace \n",
        "            indexed_text = list(map(lambda x:word_to_index(x), text[:max_length])) #map raw word string to its index   \n",
        "            if 'news' in input_file:\n",
        "                input_text.append([indexed_text,0]) \n",
        "            elif 'novel' in input_file:\n",
        "                input_text.append([indexed_text,1]) \n",
        "            elif 'article' in input_file:\n",
        "                input_text.append([indexed_text,2]) \n",
        "            elif 'encyclopedia' in input_file:\n",
        "                input_text.append([indexed_text,3]) \n",
        "            \n",
        "            f.close()\n",
        "    random.shuffle(input_text)\n",
        "    return input_text\n",
        "\n",
        "input_data = prep_data()\n",
        "train_data = input_data[:int(len(input_data)*0.6)]\n",
        "val_data = input_data[int(len(input_data)*0.6):int(len(input_data)*0.8)]\n",
        "test_data = input_data[int(len(input_data)*0.8):]\n",
        "\n",
        "train_input = [data[0] for data in train_data]\n",
        "train_input = sequence.pad_sequences(train_input, maxlen=max_length) #padding\n",
        "train_target = [data[1] for data in train_data]\n",
        "train_target=to_categorical(train_target, num_classes=4)\n",
        "\n",
        "val_input = [data[0] for data in val_data]\n",
        "val_input = sequence.pad_sequences(val_input, maxlen=max_length) #padding\n",
        "val_target = [data[1] for data in val_data]\n",
        "val_target=to_categorical(val_target, num_classes=4)\n",
        "\n",
        "test_input = [data[0] for data in test_data]\n",
        "test_input = sequence.pad_sequences(test_input, maxlen=max_length) #padding\n",
        "test_target = [data[1] for data in test_data]\n",
        "test_target=to_categorical(test_target, num_classes=4)\n",
        "\n",
        "del input_data, val_data,train_data, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjsAjAyOcr9T",
        "outputId": "abc08e21-ba46-4bd8-f0db-441c3148ca83"
      },
      "source": [
        "val_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[153544,  25982,    207, ..., 153544, 153544,   1089],\n",
              "       [  3382,     39,      1, ...,    202,    130,     13],\n",
              "       [  8544,    156,     41, ...,   5572,     58,    759],\n",
              "       ...,\n",
              "       [  4313,    907,   1273, ...,  23587,    444,     87],\n",
              "       [    74,     55,   5659, ...,    510,    266,    203],\n",
              "       [    27,     17,    750, ...,      1,     50,      8]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syrKnUxWi-YI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f4efc5-5e5e-4509-ed19-f3edd243a138"
      },
      "source": [
        "#the classification model\n",
        "#TODO#5 find out how to initialize your embedding layer with pre-trained weights, evaluate and observe\n",
        "#don't forget to compare it with the same model that does not use pre-trained weights\n",
        "#you can use your own model too! and feel free to customize this model as you wish\n",
        "cls_model = Sequential()\n",
        "cls_model.add(Embedding(len(dictionary)+1, 32, input_length=max_length,mask_zero=True))\n",
        "cls_model.add(GRU(32))\n",
        "cls_model.add(Dropout(0.5))\n",
        "cls_model.add(Dense(4, activation='softmax'))\n",
        "opt=Adam(lr=0.01)\n",
        "cls_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "cls_model.summary()\n",
        "print('Train...')\n",
        "cls_model.fit(train_input, train_target,\n",
        "          epochs=10,\n",
        "          validation_data=[val_input, val_target])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 2000, 32)          4913440   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 32)                6336      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 132       \n",
            "=================================================================\n",
            "Total params: 4,919,908\n",
            "Trainable params: 4,919,908\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n",
            "Epoch 1/10\n",
            "10/10 [==============================] - 30s 2s/step - loss: 1.3609 - accuracy: 0.3361 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 19s 2s/step - loss: 1.1892 - accuracy: 0.4179 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.6546 - accuracy: 0.7456 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.2898 - accuracy: 0.9102 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.1176 - accuracy: 0.9748 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 28s 3s/step - loss: 0.0673 - accuracy: 0.9793 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.0430 - accuracy: 0.9901 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0219 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0141 - accuracy: 0.9942 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f13e12df1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t_dK8l9H92h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11e13c8-c36a-4748-bcf4-746ad90f8e17"
      },
      "source": [
        "results = cls_model.evaluate(test_input, test_target)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 111ms/step - loss: 2.4041 - accuracy: 0.4804\n",
            "test loss, test acc: [2.4041450023651123, 0.4803921580314636]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wZU9eEkHy2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63463791-51c8-4382-a8f3-c76ddaa4a85a"
      },
      "source": [
        "cls_model_with_pretrained_weight = Sequential()\r\n",
        "cls_model_with_pretrained_weight.add(Embedding(len(dictionary)+1, 32, input_length=max_length,mask_zero=True, embeddings_initializer=tf.keras.initializers.Constant(final_embeddings)))\r\n",
        "cls_model_with_pretrained_weight.add(GRU(32))\r\n",
        "cls_model_with_pretrained_weight.add(Dropout(0.5))\r\n",
        "cls_model_with_pretrained_weight.add(Dense(4, activation='softmax'))\r\n",
        "opt=Adam(lr=0.01)\r\n",
        "cls_model_with_pretrained_weight.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\r\n",
        "cls_model_with_pretrained_weight.summary()\r\n",
        "print('Train...')\r\n",
        "cls_model_with_pretrained_weight.fit(train_input, train_target,\r\n",
        "          epochs=10,\r\n",
        "          validation_data=[val_input, val_target])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 2000, 32)          4913440   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 32)                6336      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 132       \n",
            "=================================================================\n",
            "Total params: 4,919,908\n",
            "Trainable params: 4,919,908\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n",
            "Epoch 1/10\n",
            "10/10 [==============================] - 20s 2s/step - loss: 1.4493 - accuracy: 0.3623 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 20s 2s/step - loss: 1.4477 - accuracy: 0.3600 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 20s 2s/step - loss: 1.2170 - accuracy: 0.4248 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 16s 2s/step - loss: 1.1381 - accuracy: 0.5854 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.9456 - accuracy: 0.7120 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6739 - accuracy: 0.7398 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.5031 - accuracy: 0.7991 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 16s 1s/step - loss: 0.3450 - accuracy: 0.9013 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.1875 - accuracy: 0.9557 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 16s 1s/step - loss: 0.1947 - accuracy: 0.9345 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f13b8bd84a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEnvQKECTsqk",
        "outputId": "79c67420-185d-48ae-a7f7-ce8f20e86206"
      },
      "source": [
        "results = cls_model_with_pretrained_weight.evaluate(test_input, test_target)\r\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 98ms/step - loss: 1.2922 - accuracy: 0.6176\n",
            "test loss, test acc: [1.292184591293335, 0.6176470518112183]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ086voBWJWk"
      },
      "source": [
        "### Discussion\r\n",
        "With pretrained weight, model converge better.<br>\r\n",
        "However the same analogy we used seem to be confusing now...\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txaPcJ1iTwOA"
      },
      "source": [
        "model_final_embeddings = cls_model.layers[0]\r\n",
        "model_final_embeddings_with_pretrained_weight = cls_model_with_pretrained_weight.layers[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROSLv_jtWafG",
        "outputId": "d80bc072-0f24-4844-9b97-26d3dfaf5c9d"
      },
      "source": [
        "print('Without pretrain')\r\n",
        "result_embedding = model_final_embeddings.weights[0].numpy()\r\n",
        "for i in s:\r\n",
        "  tmp = (result_embedding[dictionary[i[0]]]-result_embedding[dictionary[i[1]]]+result_embedding[dictionary[i[2]]]).reshape(1,-1)\r\n",
        "  all_dist = scipy.spatial.distance.cdist(result_embedding, tmp, 'cosine').reshape(-1)\r\n",
        "  idx = np.argpartition(all_dist,1)[:1][0]\r\n",
        "  # print(reverse_dictionary[idx])\r\n",
        "  # idx = idx[np.argsort(all_dist[idx[:3]])]\r\n",
        "  # for i in idx:\r\n",
        "  print(i[0],'-',i[1],'+',i[2],'=',reverse_dictionary[idx])\r\n",
        "  print('===========')\r\n",
        "print('\\n\\n')\r\n",
        "print('With pretrain')\r\n",
        "result_embedding = model_final_embeddings_with_pretrained_weight.weights[0].numpy()\r\n",
        "for i in s:\r\n",
        "  tmp = (result_embedding[dictionary[i[0]]]-result_embedding[dictionary[i[1]]]+result_embedding[dictionary[i[2]]]).reshape(1,-1)\r\n",
        "  all_dist = scipy.spatial.distance.cdist(result_embedding, tmp, 'cosine').reshape(-1)\r\n",
        "  idx = np.argpartition(all_dist,1)[:1][0]\r\n",
        "  # print(reverse_dictionary[idx])\r\n",
        "  # idx = idx[np.argsort(all_dist[idx[:3]])]\r\n",
        "  # for i in idx:\r\n",
        "  print(i[0],'-',i[1],'+',i[2],'=',reverse_dictionary[idx])\r\n",
        "  print('===========')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without pretrain\n",
            "แมว - หมา + สิงโต = งดงาม\n",
            "===========\n",
            "ดี - ขาว + ดำ = หรอก\n",
            "===========\n",
            "โตเกียว - ญี่ปุ่น + ไทย = ไทย\n",
            "===========\n",
            "king - man + woman = เอตู๊ด\n",
            "===========\n",
            "ขอทาน - จน + รวย = ม่าย\n",
            "===========\n",
            "เพลง - ศิลปิน + ทหาร = ตั้ง\n",
            "===========\n",
            "งง - โง่ + ฉลาด = งง\n",
            "===========\n",
            "ล้น - มาก + น้อย = น้อย\n",
            "===========\n",
            "ชอบ - รัก + หลง = กรุงเทพประกันภัย\n",
            "===========\n",
            "กษัตริย์ - ชาย + หญิง = รัฐธรรมนูญ\n",
            "===========\n",
            "\n",
            "\n",
            "\n",
            "With pretrain\n",
            "แมว - หมา + สิงโต = ผัด\n",
            "===========\n",
            "ดี - ขาว + ดำ = เดินทาง\n",
            "===========\n",
            "โตเกียว - ญี่ปุ่น + ไทย = อาศัย\n",
            "===========\n",
            "king - man + woman = และอาย\n",
            "===========\n",
            "ขอทาน - จน + รวย = สน\n",
            "===========\n",
            "เพลง - ศิลปิน + ทหาร = เพลง\n",
            "===========\n",
            "งง - โง่ + ฉลาด = ฉลาด\n",
            "===========\n",
            "ล้น - มาก + น้อย = ลายลักษณ์อักษร\n",
            "===========\n",
            "ชอบ - รัก + หลง = หลง\n",
            "===========\n",
            "กษัตริย์ - ชาย + หญิง = รอบคอบ\n",
            "===========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0wJOAg2eoQk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}